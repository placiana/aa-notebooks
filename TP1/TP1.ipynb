{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 1 \n",
    "### Clasificación sobre datos simulados. \n",
    "\n",
    "## Introducción\n",
    "Para este trabajo, hemos creado una función generadora de minions. Sobre cada minion, hemos medido 200 características que representan habilidades que poseen en distintas tareas (relacionadas al Mal).  \n",
    "\n",
    "El doctor Nefario ha ideado una fórmula para determinar si un minion es o no apto para concretar su plan para conquistar el mundo. De esta manera ha etiquetado más de 500 minions. Lamentablemente, ha perdido dicha fórmula y necesita seguir decidiendo si nuevos minions son o no aptos para su macabro plan.\n",
    "\n",
    "Es por esto que nuestro objetivo será construir clasificadores que estimen lo mejor posible la probabilidad de que nuevos minions sean o no aptos para concretar el plan de conquista y así facilitarle las cosas al doctor Nefario.\n",
    "\n",
    "Por otra parte, ya que el doctor Nefario tuvo problemas con equipos que sobreestiman sus resultados, decidió guardarse varias etiquetas extra que no compartirá con nadie, y que luego utilizará para elegir al mejor equipo, al cual contratará para (de una vez por todas) conquistar el mundo. \n",
    "\n",
    "\n",
    "En concreto:\n",
    "\n",
    "Tendrán disponible una matriz de datos $X$ de $500$ filas en donde cada fila $x^{(i)}$ representa un vector de $200$ características de cada instancia. Es decir, $\\textbf{x}^{(i)} = x_1^{(i)}, \\dots, x_{200}^{(i)}$ con $i$ entre $1$ y $500$. Además, tendrán y, un vector de $500$ posiciones con dos posibles valores: $True$ y $False$. \n",
    "\n",
    "Por otra parte, tendrán disponibles más instancias de evaluación $X_{competencia}$ sin las respectivas etiquetas que utilizaremos para evaluar sus resultados. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREAMBULOS\n",
    "%matplotlib inline\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as  pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('precision', 4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.ensemble\n",
    "\n",
    "from scipy.stats import randint as sp_randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "X = pd.read_csv(\"X.csv\", index_col=\"index\")\n",
    "y = pd.read_csv(\"y.csv\", index_col=\"index\", dtype=int)  # Cargamos los valores booleanos (True y False)\n",
    "                                                        # como números (1 y 0) para facilitar el manejo luego. \n",
    "    \n",
    "X_competencia = pd.read_csv(\"X_competencia1.csv\", index_col=\"index\")\n",
    "y_competencia_ejemplo = pd.read_csv(\"y_competencia_ejemplo.csv\", index_col=\"index\")\n",
    "#display(X)\n",
    "#display(y)\n",
    "\n",
    "# Descomentar si quieren ver los datos para la competencia:\n",
    "# display(X_competencia) \n",
    "# display(y_competencia_ejemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "### Separación de datos\n",
    "\n",
    "Contarán con una cantidad limitada de datos, por lo cual es importante tomar una buena decisión en el momento de empezar a utilizarlos. En este punto pedimos que evalúen cómo separar sus datos para desarrollo y para evaluación tomando en cuenta la competencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_dev: (450, 200), y_dev: (450, 1) para desarrollo\n",
      "X_eval: (50, 200), y_eval: (50, 1) para evaluación\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb77eba37b8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EJERCICIO 1. \n",
    "\n",
    "import sklearn.model_selection\n",
    "\n",
    "np.random.seed(666)\n",
    "\n",
    "\n",
    "########################################################\n",
    "# Objetivo: variables X_dev, X_eval, y_dev e y_eval asignadas\n",
    "\n",
    "X_dev, X_eval, y_dev, y_eval = sklearn.model_selection.train_test_split(X, y, test_size=0.1, shuffle=True, stratify=y)\n",
    "\n",
    "#########################################################\n",
    "\n",
    "\n",
    "print(\"X_dev: {}, y_dev: {} para desarrollo\".format(X_dev.shape, y_dev.shape))\n",
    "print(\"X_eval: {}, y_eval: {} para evaluación\".format(X_eval.shape, y_eval.shape))\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(131)\n",
    "plt.title('y')\n",
    "plt.hist(np.array(y))  # muestra un histograma para la distribución de y.\n",
    "plt.subplot(132)\n",
    "plt.title('y_dev')\n",
    "plt.hist(np.array(y_dev))  # muestra un histograma para la distribución de y_dev.\n",
    "plt.subplot(133)\n",
    "plt.title('y_eval')\n",
    "plt.hist(np.array(y_eval))  # muestra un histograma para la distribución de y_eval.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suponemos y asumimos que el dataset con el que contamos tiene una distribución representativa de la distribución poblacional real, y por lo tanto estratificamos la separación de los datos para desarrollo y held-out.\n",
    "Funciones utilizadas posteriormente, como por ejemplo GridSearchCV, proceden a estratificar los datos por default. Conservar datos como held-out nos brindará una referencia para medir la performance de nuestros futuros modelos para la competencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "### Construcción de modelos\n",
    "\n",
    "Para este punto, la tarea consiste en construir y evaluar modelos de tipo árbol de decisión, de manera de obtener una estimación realista de la performance de los mismos. \n",
    "\n",
    "1. Entrenar un árbol de decisión con altura máxima 3 y el resto de los hiperparámetros en default. \n",
    "2. Estimar la performance del modelo utilizando K-fold cross validation con K = 5, con las métricas “Accuracy” y “ROC AUC”. Para ello, se pide medir la performance en cada partición tanto sobre el fold de validación como sobre los folds de entrenamiento. Luego, completar la primera tabla.\n",
    "3. Entrenar árboles de decisión para cada una de las siguientes combinaciones y completar la segunda tabla.\n",
    "\n",
    "----\n",
    "\n",
    "**EJERCICIO EXTRA:** Usar la implementación de árboles de decisión que realizaron para la guía de ejercicios de la materia. Adaptarla para que cumpla con la interfaz requerida por sklearn, asegurarse de que funcione con variables continuas y reproducir las tablas anteriores.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 1 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validación)</th>\n",
       "      <th>AUC ROC (training)</th>\n",
       "      <th>AUC ROC (validación)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8301</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>0.8795</td>\n",
       "      <td>0.7126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8194</td>\n",
       "      <td>0.6556</td>\n",
       "      <td>0.8837</td>\n",
       "      <td>0.6565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.9003</td>\n",
       "      <td>0.7153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8472</td>\n",
       "      <td>0.5889</td>\n",
       "      <td>0.8942</td>\n",
       "      <td>0.5976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8310</td>\n",
       "      <td>0.7978</td>\n",
       "      <td>0.8712</td>\n",
       "      <td>0.8194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy (training)  Accuracy (validación)  AUC ROC (training)  \\\n",
       "0               0.8301                 0.7033              0.8795   \n",
       "1               0.8194                 0.6556              0.8837   \n",
       "2               0.8500                 0.6667              0.9003   \n",
       "3               0.8472                 0.5889              0.8942   \n",
       "4               0.8310                 0.7978              0.8712   \n",
       "\n",
       "   AUC ROC (validación)  \n",
       "0                0.7126  \n",
       "1                0.6565  \n",
       "2                0.7153  \n",
       "3                0.5976  \n",
       "4                0.8194  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb77cb38748>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from arbol import MiClasificadorArbol\n",
    "accuracies_training = []\n",
    "accuracies_validation = []\n",
    "aucs_training = []\n",
    "aucs_validation = []\n",
    "\n",
    "# Puede serles de utilidad tener a X_dev e y_dev como matrices de numpy directamente:\n",
    "X_dev_np = np.array(X_dev)\n",
    "y_dev_np = np.array(y_dev).ravel()\n",
    "\n",
    "\n",
    "########################################################\n",
    "## Objetivo: accuracies_training, accuracies_validation, aucs_training y aucs_validation asignados\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "scores = cross_validate(tree, X_dev, y_dev, scoring=[\"roc_auc\", \"accuracy\"], return_train_score=True, cv=5)\n",
    "tabla1 = pd.DataFrame(scores)\n",
    "\n",
    "accuracies_training = tabla1[['train_accuracy']]\n",
    "accuracies_validation = tabla1[['test_accuracy']]\n",
    "aucs_training = tabla1[['train_roc_auc']]\n",
    "aucs_validation = tabla1[['test_roc_auc']]\n",
    "\n",
    "#########################################################\n",
    "\n",
    "df = pd.DataFrame(index=range(0,5))\n",
    "#df.index.name = \"Permutación\"\n",
    "                  \n",
    "df[\"Accuracy (training)\"] = accuracies_training\n",
    "df[\"Accuracy (validación)\"] = accuracies_validation\n",
    "df[\"AUC ROC (training)\"] = aucs_training\n",
    "df[\"AUC ROC (validación)\"] = aucs_validation\n",
    "\n",
    "\n",
    "display(HTML(\"<h3> TABLA 1 </h3>\"))\n",
    "display(df)\n",
    "\n",
    "# Descomentar las siguientes líneas para graficar el resultado\n",
    "df.plot(kind=\"bar\")\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 1 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validación)</th>\n",
       "      <th>AUC ROC (training)</th>\n",
       "      <th>AUC ROC (validación)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy (training)  Accuracy (validación)  AUC ROC (training)  \\\n",
       "0                  1.0                   0.80                 1.0   \n",
       "1                  1.0                   0.55                 1.0   \n",
       "2                  1.0                   0.75                 1.0   \n",
       "3                  1.0                   0.75                 1.0   \n",
       "4                  1.0                   0.65                 1.0   \n",
       "\n",
       "   AUC ROC (validación)  \n",
       "0                0.7802  \n",
       "1                0.5220  \n",
       "2                0.7500  \n",
       "3                0.7500  \n",
       "4                0.6500  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb77c784ef0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from arbol import MiClasificadorArbol\n",
    "accuracies_training = []\n",
    "accuracies_validation = []\n",
    "aucs_training = []\n",
    "aucs_validation = []\n",
    "\n",
    "# Puede serles de utilidad tener a X_dev e y_dev como matrices de numpy directamente:\n",
    "X_dev_short = np.array(X_dev.head(100))\n",
    "y_dev_short = np.array(y_dev.head(100)).ravel()\n",
    "\n",
    "\n",
    "########################################################\n",
    "## Objetivo: accuracies_training, accuracies_validation, aucs_training y aucs_validation asignados\n",
    "\n",
    "tree = MiClasificadorArbol()\n",
    "\n",
    "scores = cross_validate(tree, X_dev_short, y_dev_short, scoring=[\"roc_auc\", \"accuracy\"], return_train_score=True, cv=5)\n",
    "tabla1 = pd.DataFrame(scores)\n",
    "\n",
    "accuracies_training = tabla1[['train_accuracy']]\n",
    "accuracies_validation = tabla1[['test_accuracy']]\n",
    "aucs_training = tabla1[['train_roc_auc']]\n",
    "aucs_validation = tabla1[['test_roc_auc']]\n",
    "\n",
    "#########################################################\n",
    "\n",
    "df = pd.DataFrame(index=range(0,5))\n",
    "#df.index.name = \"Permutación\"\n",
    "                  \n",
    "df[\"Accuracy (training)\"] = accuracies_training\n",
    "df[\"Accuracy (validación)\"] = accuracies_validation\n",
    "df[\"AUC ROC (training)\"] = aucs_training\n",
    "df[\"AUC ROC (validación)\"] = aucs_validation\n",
    "\n",
    "\n",
    "display(HTML(\"<h3> TABLA 1 </h3>\"))\n",
    "display(df)\n",
    "\n",
    "# Descomentar las siguientes líneas para graficar el resultado\n",
    "df.plot(kind=\"bar\")\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "resultados_training = []\n",
    "resultados_validation = []\n",
    "\n",
    "########################################################\n",
    "## Objetivo: resultados_training y resultados_validation asignadas\n",
    "\n",
    "param_grid = {'criterion' : ('gini', 'entropy'), 'max_depth' : (3, 5, None)}\n",
    "\n",
    "gs = GridSearchCV(DecisionTreeClassifier(), param_grid, scoring=\"roc_auc\",\n",
    "                  n_jobs=-1, cv=5, return_train_score=True)\n",
    "gs.fit(X_dev, y_dev)\n",
    "tabla2 = pd.DataFrame(gs.cv_results_)\n",
    "\n",
    "resultados_training = tabla2[['mean_train_score']]\n",
    "resultados_validation = tabla2[['mean_test_score']]\n",
    "\n",
    "#########################################################\n",
    "\n",
    "df = pd.DataFrame(index=range(0,6))\n",
    "\n",
    "df[\"Altura máxima\"] = [3, 5, \"Inifinito\"] * 2\n",
    "df[\"Criterio de evaluación de corte\"] = [\"Gini\"] * 3 + [\"Ganancia de Información\"] * 3\n",
    "df[\"AUC ROC Promedio en Training\"] = resultados_training\n",
    "df[\"AUC ROC Promedio en Validación\"] = resultados_validation\n",
    "\n",
    "\n",
    "display(HTML(\"<h3> TABLA 2 </h3>\"))\n",
    "display(df)\n",
    "print('Mejores Parámetros', gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya sea utilizando tanto Gini ó Entropia como criterio de corte para el árbol de decisiones, se puede apreciar que al aumentar el parámetro de altura máxima el puntaje promedio de entrenamiento aumenta pero esta tendencia no se ve respaldada por los puntajes obtenidos en validación, un claro caso de overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Comparación de algoritmos\n",
    "\n",
    "\n",
    "Se pide explorar distintas combinaciones de algoritmos de aprendizaje e hiperparámetros, de manera de buscar una performance óptima. Para este ejercicio es necesario que evalúen posibilidades utilizando la técnica de Grid Search. Como métrica de performance, usar siempre el área bajo la curva (AUC ROC) resultante de 5-fold cross-validation. \n",
    "\n",
    "Algoritmos a probar: KNN, árboles de decisión, LDA, Naive Bayes y SVM. Hiperparámetros: Revisar la documentación de cada uno para la búsqueda de combinaciones prometedoras.  \n",
    "\n",
    "Se pide generar un reporte que contenga: \n",
    "\n",
    "1. Una descripción de las distintas combinaciones consideradas y su performance asociada (las que consideren relevantes, con al menos la mejor combinación para cada algoritmo). \n",
    "\n",
    "1. Una breve explicación de los factores que creen que produjeron dicho resultado. \n",
    "\n",
    "En este punto evaluaremos tanto los hiperparámetros elegidos como las conclusiones relacionadas a por qué piensan que ciertos algoritmos funcionan mejor que otros para estos datos. \n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "**EJERCICIO EXTRA**: Utilizar RandomizedSearchCV con rangos de parámetros que contengan a los utilizados en el GridSearch. Analizar si se encontraron mejores combinaciones de parámetros que no hayan sido tenidas en cuenta con el GridSearch y cuál fue la diferencia de tiempo de ejecución. \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de comenzar procedemos a realizar un preprocesamiento de nuestros datos para adaptarlos correctamente a los requirimientos de las hipotesis de cada algoritmo.\n",
    "\n",
    "La estandarización de los datos implica, para cada feature por separado, restar la media para centrar en cero y dividir para la varianza para normalizar en función de esta. Mientras que el re-escalado transforma el rango de valores de cada feature proporcionalmente entre 0 y 1.\n",
    "\n",
    "Algoritmos como Naive Bayes suelen verse beneficiados por este preprocesamiento de los datos demostrando una mejor performance, mientras que otros como Support Vector Machine (en especial con su su kernel radial basis function, RBF) asumen que los datos ya se encuentran en este formato y resulta por lo tanto un requerimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_dev_std = StandardScaler().fit_transform(X_dev_np)\n",
    "\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "X_dev_minmax = minmax_scale(X_dev_np)\n",
    "\n",
    "# Resampleo\n",
    "from sklearn.utils import resample\n",
    "X_rs, y_rs = resample(X_dev_std, y_dev, n_samples=500)\n",
    "X_rs = np.array(X_rs)\n",
    "y_rs = np.array(y_rs).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "## Si quieren, pueden utilizar esta función para imprimir las mejores combinaciones de su grid\n",
    "def top_resultados(grid, top=5):\n",
    "    print(\"Top {} Combinaciones\".format(top))\n",
    "    df = pd.DataFrame(grid.cv_results_[\"params\"])\n",
    "    df[\"AUC ROC Promedio en Training\"] = grid.cv_results_[\"mean_train_score\"]\n",
    "    df[\"AUC ROC Promedio en Validacion\"] = grid.cv_results_[\"mean_test_score\"]\n",
    "    display(df.sort_values(by=\"AUC ROC Promedio en Validacion\", ascending=False).head(top))\n",
    "\n",
    "\n",
    "def print_results(grid_search, title, X_eval, y_eval):\n",
    "    print(title)\n",
    "    top_resultados(grid_search, top=5)\n",
    "    print(\"Parametros elegidos: {}\".format(grid_search.best_params_))\n",
    "    print(\"Mejor AUC ROC: {:.4f}\".format(grid_search.best_score_))\n",
    "    print(\"AUC ROC obtenido en Held On: {:.4f}\\n\".format(roc_auc_score(y_eval, grid_search.predict(X_eval))))\n",
    "    \n",
    "########################################################\n",
    "## Objetivo: comparar y explorar distintas combinaciones de parámetros para los algoritmos importados arriba\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "# (n_neighbors, weights, algorithm, leaf_size, p, metric, metric_params, n_jobs)\n",
    "\n",
    "param_grid = {'n_neighbors': [1, 5, 10, 15, 20, 25, 30, 35, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50],\n",
    "              'weights': ['uniform', 'distance'],\n",
    "              # 'algorithm': ['ball_tree', 'kd_tree', 'brute'], # esto no modifica mucho\n",
    "              'p': [1, 2]\n",
    "             }\n",
    "gs = GridSearchCV(KNeighborsClassifier(), param_grid, scoring=\"roc_auc\", cv=5, n_jobs=-1).fit(X_dev, y_dev_np)\n",
    "knn_model = gs.best_estimator_\n",
    "print_results(gs, \"K-Nearest Neighbors\", X_eval, y_eval)\n",
    "\n",
    "\n",
    "# Scaled K-Nearest Neighbors\n",
    "# (n_neighbors, weights, algorithm, leaf_size, p, metric, metric_params, n_jobs)\n",
    "gs = GridSearchCV(KNeighborsClassifier(), param_grid, scoring=\"roc_auc\", cv=5, n_jobs=-1).fit(X_dev_std, y_dev_np)\n",
    "print_results(gs, \"K-Nearest Neighbors STD\", X_eval, y_eval)\n",
    "\n",
    "\n",
    "# Scaled K-Nearest Neighbors just uniform\n",
    "# (n_neighbors, weights, algorithm, leaf_size, p, metric, metric_params, n_jobs)\n",
    "gs = GridSearchCV(KNeighborsClassifier(),\n",
    "                  {'n_neighbors': [1, 5, 10, 15, 20, 25, 30, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], 'p': [1, 2]},\n",
    "                  scoring=\"roc_auc\", cv=5, n_jobs=-1).fit(X_rs, y_rs)\n",
    "print_results(gs, \"K-Nearest Neighbors STD con Peso Uniforme y Diferentes Funciones de Distancia\", X_eval, y_eval)\n",
    "\n",
    "# Linear Discriminant Analysis\n",
    "# (solver, shrinkage, priors, n_components, store_covariance, tol)\n",
    "param_grid = {'solver': ['svd', 'lsqr', 'eigen']}\n",
    "gs = GridSearchCV(LinearDiscriminantAnalysis(), param_grid, scoring=\"roc_auc\", cv=5, n_jobs=-1\n",
    "                 ).fit(X_dev, y_dev_np)\n",
    "print_results(gs, \"Linear Discriminant Analysis\", X_eval, y_eval)\n",
    "\n",
    "# Decision Tree\n",
    "# (criterion, splitter, max_depth, min_samples_split, min_samples_leaf, min_weight_fraction_leaf, max_features,\n",
    "# random_state, max_leaf_nodes, min_impurity_decrease, min_impurity_split, class_weight, presort)\n",
    "param_grid = {'criterion': ['gini', 'entropy'], 'max_depth': [1, 2, 3, 4, 5, 6, 7, None]}\n",
    "gs = GridSearchCV(DecisionTreeClassifier(), param_grid, scoring=\"roc_auc\", cv=5, n_jobs=-1).fit(X_dev, y_dev_np)\n",
    "\n",
    "print_results(gs, \"Decision Tree\", X_eval, y_eval)\n",
    "tree_best_params = gs.best_params_\n",
    "\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "true_ratio = np.sum(y_dev_np) / y_dev_np.size\n",
    "param_grid = {'priors': [[1-true_ratio, true_ratio], [0.1, 0.9],[0.4, 0.6],[0.5, 0.5],[0.6, 0.4], [0.9, 0.1]]}\n",
    "nb_estimator = GaussianNB()\n",
    "grid_search = GridSearchCV(nb_estimator, param_grid, scoring=\"roc_auc\", cv=5).fit(X_dev_np, y_dev_np)\n",
    "#grid_search = GridSearchCV(nb_estimator, param_grid, scoring=\"roc_auc\", cv=5, n_jobs=-1).fit(X_rs, y_rs)\n",
    "print_results(grid_search, \"Gaussian Naive Bayes\", X_eval, y_eval)\n",
    "\n",
    "\n",
    "# Support Vector Classification con entrada estandarizada\n",
    "# (C, kernel, degree, gamma, coef0, shrinking, probability, tol, cache_size,\n",
    "# class_weight, verbose, max_iter, decision_function_shape, random_state)\n",
    "svc_params_gamma = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100]\n",
    "svc_params_c = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100] \n",
    "param_grid = {\n",
    "    'C': svc_params_c,\n",
    "    'kernel': [\"linear\", \"poly\", \"rbf\", ],#\"sigmoid\"],\n",
    "    'gamma': svc_params_gamma\n",
    "}\n",
    "gs = GridSearchCV(SVC(), param_grid, scoring=\"roc_auc\", cv=5, n_jobs=-1).fit(X_dev_std, y_dev_np)\n",
    "print_results(gs, \"Support Vector Classification STD\", X_eval, y_eval)\n",
    "svc_best_params = gs.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones Grid Search\n",
    "\n",
    "### K Nearest Neighbors\n",
    "Realizamos una busqueda para los parámetros *cantidad de vecinos*, la función *peso* para la influencia de cada vecino en la decisión final, y el parámetro *p* que establece qué definición de distancia se utilizará. Cuando el peso del vecino se define por la inversa de la distancia (aquellos más cercanos son mas significativos), el ajuste sobre los datos de entrenamiento alcanza una predicción perfecta, típico indicador de un posible overfitting. En cambio, cuando se utiliza un peso *uniforme*, se observa una ligera disminución en los puntajes de entrenamiento pero con puntajes de validación similares y más próximos entre si. Esto significa que estos modelos con peso uniforme presentan una baja varianza.\n",
    "Dada la naturaleza geométrica del algoritmo, decidimos probar estandarizando los datos de entrada. Comprobamos un puntaje similar en validación aunque una leve mejora en el puntaje del modelo sobre el held-out. También, al realizar una búsqueda local y fijar el peso en *uniforme*, encontramos mejorías en este sentido.\n",
    "\n",
    "### Arbol de decisión\n",
    "Completamos el analisis hecho en el punto anterior con otros valores para el parámetro max_depth en el rango de 1 a 7 e infinito. Pese a que nuestros datos cuentan con una cantidad grande de features los mejores árboles tienen una altura máxima de 3 o 4. Con una altura de 5 ya vemos que el modelo \"overfittea\" de entrenamiento (0.97) y comienza a empeorar con los datos de validación. Esta es una característica propia de este algoritmo: no es muy util contar con un solo árbol muy profundo.\n",
    "\n",
    "### Naive Bayes\n",
    "Este algoritmo no es muy parametrizable. Decidimos entonces probar como afectaba cambiar las probabilidades a priori. Calculamos una aproximación de acuerdo a la proporcion en el dataset de entrenamiento y despues completamos con probabilidades complementarias entre 0 y 1. La busqueda con grid search muestra que no hubo variacion y todos los modelos tienen el mismo rendimiento con cualquier probabilidad a priori que le definamos.\n",
    "Los resultados no son muy buenos ni para los datos de entrenamiento (rondando los 0.85) pero vemos que estos puntajes son muy cercanos a los de validación. Este resultado sugiere que nuestros modelos tienen un sesgo alto pero una varianza baja. Esto se puede deber a que el algoritmo utilizado asume fuertemente que la distribución de los datos es gaussiana.\n",
    "\n",
    "### LDA\n",
    "Cambiar el método de cómputo de la matriz de covarianza no modificó los resultados obtenidos.\n",
    "\n",
    "### Support vector machines\n",
    "\n",
    "Varíamos los parámetros *c*, *gamma* y el tipo de kernel. De este último hiperparámetro parece haber consenso en que RBF es el que mejor funciona para nuestro problema. Dado que SVM sufre con datos muy dispersos, alimentamos el modelo cambiando la escala de los datos de entrenamiento. Es destacable que con este modelo obtuvimos el mejor puntaje para la partición held-out. Probablemente una posterior busqueda focalizada con paso más fino podría incrementar el puntaje. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: \n",
    "### Diagnóstico Sesgo-Varianza. \n",
    "\n",
    "En este punto, se pide inspeccionar dos de sus mejores modelos encontrados hasta ahora: el mejor modelo de tipo árbol de decisión y el mejor de tipo SVM. Para ello:\n",
    "\n",
    "1. Graficar curvas de complejidad para cada modelo, variando la profundidad en el caso de árboles, y el hiperparámetro C en el caso de SVM. Diagnosticar cómo afectan al sesgo y a la varianza esos dos hiperparámetros.\n",
    "2. Graficar curvas de aprendizaje para cada modelo. En base a estas curvas, sacar conclusiones sobre si los algoritmos parecen haber alcanzado su límite, o bien si aumentar la cantidad de datos debería ayudar.\n",
    "3. Construir un modelo RandomForest con 200 árboles. Explorar para qué sirve el hiperparámetro max_features y cómo afecta a la performance del algoritmo mediante una curva de complejidad. Explicar por qué creen que se dieron los resultados obtenidos. Por último, graficar una curva de aprendizaje sobre los parámetros elegidos para determinar si sería útil o no conseguir más datos (usar  grid search para encontrar una buena combinación de parámetros).  \n",
    "\n",
    "\n",
    "**Atención**: Tener en cuenta que debemos seguir utilizando ROC AUC como métrica para estas curvas.\n",
    "\n",
    "**ver**: http://scikit-learn.org/stable/modules/learning_curve.html#learning-curve\n",
    "\n",
    "----\n",
    "**EJERCICIO EXTRA:** Utilizar RandomizedSearchCV para explorar la performance del algoritmo de Gradient Boosting y comparar con los resultados obtenidos en el punto (c).\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "def print_validation_curve(title, param_range, train_scores, test_scores):\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.title('Curva de validación ' + title)\n",
    "    plt.xlabel(title)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.ylim(0.0, 1.1)\n",
    "    lw = 2\n",
    "    plt.plot(param_range, train_scores_mean, label=\"Puntaje Promedio en Training\", color=\"darkorange\", lw=lw)\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                     color=\"darkorange\", lw=lw)\n",
    "    plt.plot(param_range, test_scores_mean, label=\"Puntaje Promedio en Validación\",\n",
    "                 color=\"navy\", lw=lw)\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                     color=\"navy\", lw=lw)\n",
    "    plt.legend(loc=\"best\")\n",
    "    #plt.show()\n",
    "\n",
    "def print_validation_curve_log(title, param_range, train_scores, test_scores):\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.title('Curva de validación ' + title)\n",
    "    plt.xlabel(title)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.ylim(0.0, 1.1)\n",
    "    lw = 2\n",
    "    plt.semilogx(param_range, train_scores_mean, label=\"Puntaje Promedio en Training\", color=\"darkorange\", lw=lw)\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                     color=\"darkorange\", lw=lw)\n",
    "    plt.semilogx(param_range, test_scores_mean, label=\"Puntaje Promedio en Validación\",\n",
    "                 color=\"navy\", lw=lw)\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                     color=\"navy\", lw=lw)\n",
    "    plt.legend(loc=\"best\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[14, 5])\n",
    "\n",
    "# Arbol\n",
    "estimator = DecisionTreeClassifier().set_params(**tree_best_params)\n",
    "\n",
    "# Altura\n",
    "param_range = [1, 2, 3, 4, 5, 6, 7, 10]\n",
    "train_scores, test_scores = validation_curve(estimator, X_dev_np, y_dev_np, param_name=\"max_depth\", \n",
    "                                             param_range=param_range, cv=10,\n",
    "                                             scoring=\"roc_auc\", n_jobs=-1)\n",
    "\n",
    "plt.subplot(121)\n",
    "print_validation_curve('max_depth', param_range, train_scores, test_scores)\n",
    "plt.ylim(0.5, 1.1)\n",
    "\n",
    "\n",
    "param_range = [3, 6, 10, 20, 30]\n",
    "train_scores, test_scores = validation_curve(estimator, X_dev_np, y_dev_np, param_name=\"max_depth\", \n",
    "                                             param_range=param_range, cv=10,\n",
    "                                             scoring=\"roc_auc\", n_jobs=-1)\n",
    "\n",
    "plt.subplot(122)\n",
    "print_validation_curve('max_depth', param_range, train_scores, test_scores)\n",
    "plt.ylim(0.5, 1.1)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva de validación - Árbol de decisión\n",
    "En el primer gráfico vemos que para un valor de 3 en la altura máxima del arbol se alcanza un máximo en el puntaje. En este valor la varianza no es muy grande. Luego, a partir de un valor de 6, el sesgo hacia los datos de entrenamiento se vuelve muy grande y los modelos comienzan a dar peores resultados.\n",
    "\n",
    "En el segundo gráfico analiza los valores sucesivos a mayor escala donde vemos que, aproximadamente a partir de un valor de altura de 10, el puntaje se comporta de manera asintótica y el algoritmo nunca presenta una mejora.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SVC\n",
    "plt.figure(figsize=[14, 5])\n",
    "print(\"Support Vector Machine\")\n",
    "\n",
    "# Gamma\n",
    "plt.subplot(121)\n",
    "\n",
    "estimator = SVC().set_params(**svc_best_params)\n",
    "param_range = svc_params_gamma\n",
    "train_scores, test_scores = validation_curve(estimator, X_dev_std, y_dev_np, param_name=\"gamma\", \n",
    "                                             param_range=param_range, cv=5, scoring=\"roc_auc\", n_jobs=-1)\n",
    "\n",
    "print_validation_curve_log(\"$\\gamma$\", param_range, train_scores, test_scores)\n",
    "plt.ylim(0.3, 1.1)\n",
    "# C\n",
    "plt.subplot(122)\n",
    "\n",
    "estimator = SVC().set_params(**svc_best_params)\n",
    "param_range = svc_params_c\n",
    "train_scores, test_scores = validation_curve(estimator, X_dev_std, y_dev_np, param_name=\"C\", \n",
    "                                             param_range=param_range, cv=5, scoring=\"roc_auc\", n_jobs=-1)\n",
    "print_validation_curve_log('C', param_range, train_scores, test_scores)\n",
    "plt.ylim(0.7, 1.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curvas de validación - Support Vector Machines\n",
    "\n",
    "En la curva de validación del parámetro _C_ vemos que con un valor superior o igual a 1 la varianza aumenta. En ese valor la curva de validación alcanza su máximo. Luego el sesgo hacia los datos de entrenamiento aumenta, lo cual es consistente con lo que representa el parámetro _C_. Valores grandes de _C_ minimizan el margen entre el hiperplano y los vectores soporte, mientras que valores pequeños resultan en un hiperplano con margenes grandes, con la posibilidad de clasificar mal algunas instancias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Puntaje\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, \n",
    "                                                            train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Puntaje Promedio en Training\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Puntaje Promedio en Validación\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=[16,3])\n",
    "plt.subplot(131)\n",
    "print(\"Árbol de Decisiones - Parametros: {}\".format(tree_best_params))\n",
    "title = \"Árbol de Decisiones - Curvas de Aprendizaje\"\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "estimator = DecisionTreeClassifier().set_params(**tree_best_params)\n",
    "\n",
    "plot_learning_curve(estimator, title, X_dev_np, y_dev_np, ylim=(0.5, 1.01), cv=cv, n_jobs=-1)\n",
    "\n",
    "\n",
    "plt.subplot(132)\n",
    "\n",
    "\n",
    "print(\"SVM - Parametros: {}\".format(svc_best_params))\n",
    "title = \"SVM - Curvas de Aprendizaje\"\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "estimator = SVC().set_params(**svc_best_params)\n",
    "\n",
    "plot_learning_curve(estimator, title, X_dev_np, y_dev_np, ylim=(0.5, 1.01), cv=cv, n_jobs=-1)\n",
    "\n",
    "plt.subplot(133)\n",
    "# Naive Bayes\n",
    "plot_learning_curve(grid_search.best_estimator_, 'Naive Bayes - Curvas de Aprendizaje', X_dev_np, y_dev_np, ylim=(0.0, 1.01), cv=cv, n_jobs=-1)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curvas de aprendizaje\n",
    "\n",
    "Mediante las curvas de aprendizaje podemos determinar si el modelo se veria beneficiado por agregado de más muestras para entrenamiento. Si tanto el puntaje de validación como el puntaje de entrenamiento convergen hacia un valor bajo, entonces al aumentar el tamaño del set con el cual se realiza el entrenamiento no repercutiría significativamente en los resultados obtenidos. Tanto Naive Bayes como SVM al parecer ya se estabilizaron y su performance no parece mejorar con el agregado de nuevas muestras. En cambio, el algoritmo de árbol de decisiones muestra una pendiente creciente indicando una posible mejora al contar con un conjunto de entrenamiento mayor al actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Construir un modelo RandomForest con 200 árboles. Explorar para qué sirve el hiperparámetro max_features y cómo afecta a la performance del algoritmo mediante una curva de complejidad. Explicar por qué creen que se dieron los resultados obtenidos. Por último, graficar una curva de aprendizaje sobre los parámetros elegidos para determinar si sería útil o no conseguir más datos (usar  grid search para encontrar una buena combinación de parámetros).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "random_forest_model = RandomForestClassifier(n_estimators=200, max_depth=None,min_samples_split=2, n_jobs=-1)\n",
    "\n",
    "#Buscamos hiperparametros con grid search\n",
    "param_grid = {'max_features': np.arange(6, 25,1),\n",
    "              'n_estimators': [10, 100, 110, 200],\n",
    "              'max_depth': [3, 5, None],\n",
    "              'min_samples_split': [2, 3, 5]\n",
    "             }\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    random_forest_model, param_grid, scoring=\"roc_auc\", cv=5, n_jobs=-1).fit(X_dev_np, y_dev_np)\n",
    "print_results(grid_search, 'Random Forest', X_eval, y_eval)\n",
    "random_forest_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "#param_range = ['auto', 'sqrt', 'log2']\n",
    "#estimator = RandomForestClassifier(max_depth=None,min_samples_split=2, n_jobs=-1)\n",
    "#param_range = np.linspace(10, 200, 10, dtype=int)\n",
    "\n",
    "plt.figure(figsize=[14,8])\n",
    "#param_range = np.linspace(0.1, 0.4, 9)\n",
    "param_range = [7, 14, 15, 44, 74, 100, 200]\n",
    "train_scores, test_scores = validation_curve(random_forest_model, X_dev_np, y_dev_np,\n",
    "                                             param_name=\"max_features\", param_range=param_range,\n",
    "                                             cv=10, n_jobs=-1)\n",
    "plt.subplot(221)\n",
    "print_validation_curve('max_features', param_range, train_scores, test_scores)\n",
    "plt.ylim(0.6, 1.1)\n",
    "\n",
    "param_range = np.arange(6, 25,1)\n",
    "train_scores, test_scores = validation_curve(random_forest_model, X_dev_np, y_dev_np,\n",
    "                                             param_name=\"max_features\", param_range=param_range,\n",
    "                                             cv=10, n_jobs=-1)\n",
    "plt.subplot(222)\n",
    "print_validation_curve('max_features', param_range, train_scores, test_scores)\n",
    "plt.ylim(0.6, 1.1)\n",
    "\n",
    "\n",
    "\n",
    "#param_range = [10, 100, 110, 200, 300, 400]\n",
    "#train_scores, test_scores = validation_curve(random_forest_model, X_dev_np, y_dev_np,\n",
    "#                                             param_name=\"n_estimators\", param_range=param_range,\n",
    "#                                             cv=10, n_jobs=-1)\n",
    "\n",
    "#plt.subplot(223)\n",
    "#print_validation_curve('n_estimators', param_range, train_scores, test_scores)\n",
    "#plt.ylim(0.6, 1.1)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro *max_features* representa la cantidad de features con los que va a disponer el algoritmo a la hora de dividir cada nodo. El hecho de tener un subconjunto elegido al azar en cada nodo es lo que provee de aleatoriedad al algoritmo y produce que todos los arboles sean distintos entre si.\n",
    "La bibliografía sugiere valores cercanos a la raiz cuadrada (14) o al log_2 (7) del total de features (200).\n",
    "\n",
    "La busqueda devuelve que los mejores parámetros son:\n",
    "- altura: indefinida. Esto es consistente con la teoría. Los arboles del bosque deben ser altos para ser diferentes entre si y aportar información distinta entre si.\n",
    "\n",
    "- max_features: 7. El valor coincide con el logaritmo en base 2 del total de features. Sin embargo, en las curvas de validación vemos que no hay mucha variabilidad al cambiar este parámetro. Tanto en la busqueda general como en la local (con valores pequeños entre 6 y 25) vemos que los puntajes se mueven entre 0.7 y 0.8. Esto puede significar que los modelos no se están beneficiando de la aleatoriedad de los árboles y que nuestro problema, nuestros datos, tampoco tienen esa característica.\n",
    "\n",
    "- n_estimators: 110. En esta y otras pruebas obsevamos que a partir del valor 100 o 110 en la cantidad de árboles el algoritmo deja de mejorar.\n",
    "\n",
    "- min_samples_split: 3. Este parámetro controla la cantidad mínima en que debe dividirse un nodo. La búsqueda no provee resultados concluyentes para afirmar que un valor es mejor que otro. Los resultados son bastante parecidos.\n",
    "\n",
    "\n",
    "El puntaje de la mejor combinación de parámetros en held-out no es muy bueno en comparacion con los modelos que estudiamos anteriormente. Tambien vemos que los mejores resultados de la búsqueda muestran un sobreajuste en los datos de prueba y un puntaje (0.85) bastante alejado para las instancias de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[16, 5])\n",
    "plt.subplot(121)\n",
    "plot_learning_curve(\n",
    "    random_forest_model,\n",
    "    'Curva de aprendizaje Random Forest',\n",
    "    X_dev_np, y_dev_np, \n",
    "    ylim=(0.6, 1.01), cv=cv, n_jobs=-1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La curva de aprendizaje muestra una mejoría, tenue pero clara, a medida que aumentan las instancias de prueba. Esto nos sugiere que sí sería útil contar con mas instancias de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competencias\n",
    "\n",
    "La entrega del trabajo estará acompañada de una competencia en la cual deberán poner a prueba su mejor modelo y sobre todo, su capacidad para estimar sus resultados. \n",
    "\n",
    "Su tarea será estimar la performance (AUC ROC) que tendrá su mejor modelo en datos de evaluación (X_competencia). \n",
    "\n",
    "Para ello, deberán predecir las probabilidades de las distintas instancias con su modelo, enviarnos dichas probabilidades junto a una estimación con 4 decimales de cuál será el AUC ROC resultante y calcularemos el resultado real. El grupo que consiga acercarse más al valor real, será el grupo ganador.  \n",
    "\n",
    "Recomendamos no perder de vista esta competencia en el momento de separar los datos en los primeros puntos. \n",
    "\n",
    "Para esto, junto con la entrega del informe, deberán enviar un archivo en formato csv con las columnas “index” y “output” (ver ejemplo de archivo en: [y_competencia_ejemplo.csv](https://github.com/pbrusco/aa-notebooks/blob/master/TP1/y_competencia_ejemplo.csv)) y un valor esperado de AUC ROC. \n",
    "\n",
    "\n",
    "## Entrega\n",
    "- Contarán con un esqueleto en formato Jupyter Notebook en donde tendrán que completar las celdas faltantes (ya sea con explicaciones y gráficos o código). \n",
    "- El notebook final deberá ser entregado en formatos .html e .ipynb. Es necesario que los resultados puedan reproducirse al ejecutar todas las celdas en orden (Kernel - Restart and Run All) utilizando las bibliotecas requeridas en el archivo: requirements.txt del repositorio. \n",
    "- Tienen tiempo hasta las 23:59hs del día miércoles 17/10/2018. La entrega se debe realizar a través del campus virtual y debe contener el informe.\n",
    "- El trabajo deberá elaborarse en grupos de 3 personas.\n",
    "- Se podrán pedir pruebas de integridad y autoría; es decir, verificar que la salida solicitada es fruto del modelo presentado y que el modelo fue construido según lo requerido en este enunciado.\n",
    "- La evaluación será grupal y se basará en la calidad del informe (presentación, claridad, prolijidad); la originalidad, practicidad y coherencia técnica de la solución; la corrección y solidez de las pruebas realizadas.\n",
    "- En el primer parcial se incluirá una pregunta sobre la solución entregada. Esa pregunta no influirá en la nota del parcial, pero sí en la nota individual del TP1.\n",
    "- La participación en la competencia es obligatoria. De todas maneras, el resultado no incidirán en la nota de la materia.\n",
    "- Los ejercicios extra son opcionales para aprobar el TP, pero son obligatorios para promocionar la materia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estratégia para la Competencia\n",
    "\n",
    "Según lo conversado en clase, será declarado ganador de la competencia aquel grupo que mejor pueda predecir su propio desempeño. Por lo tanto, lo importante no es focalizar la atención en alcanzar un gran puntaje en validación o en la partición held-out, sino en elegir aquel modelo que muestre la mayor consistencia en todos los resultados, es decir la menor diferencia entre todas sus evaluaciones.\n",
    "\n",
    "De los modelos ensayados, el algoritmo KNN con *cantidad de vecinos* alrededor de 40 y *peso uniforme* fue el que mostró estas caracteristicas.\n",
    "\n",
    "Como dijimos al comienzo, si suponemos que el dataset con el que contamos tiene una distribución representativa de la distribución poblacional real, al utilizar un modelo con algoritmo KNN que utilice como parámetro de *vecinos cercanos* un número suficientemente grande (próximo ó más grande que la muestra a predecir en si), y como una función de *peso* el criterio *uniforme*, la predicción para cada instancia sería el de la mayoria con un porcentaje de acierto posiblemente cercano a los porcentajes de tal distribución. Siguiendo esta estrategia, incluso se podria configurar una función random con probabilidad equivalente a dicha distribución y se obtendrian resultados similares. Sin embargo, al no tener certeza sobre nuestra suposición es probable que esta táctica pueda ser erronea."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aa",
   "language": "python",
   "name": "aa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
